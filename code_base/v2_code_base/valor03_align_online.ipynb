{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d58be3",
   "metadata": {},
   "source": [
    "# VALOR‚Äë32K Online Builder (Images + Audio ‚Üí Parquet)\n",
    "\n",
    "This notebook builds a **tri‚Äëmodal-friendly** dataset from VALOR‚Äë32K annotations **without** storing video clips permanently on disk.\n",
    "\n",
    "For each annotation:\n",
    "\n",
    "1. Parse `video_id` ‚Üí `yt_id`, `start`, `end`.\n",
    "2. Use **yt‚Äëdlp** to download *only the segment* to a **temporary file**.\n",
    "3. Extract:\n",
    "   - a middle **video frame** ‚Üí JPEG bytes\n",
    "   - the full **audio segment** ‚Üí 16kHz mono WAV bytes\n",
    "4. Delete the temporary file immediately.\n",
    "5. Store a row in memory with:\n",
    "   - `video_id`, `yt_id`, `start`, `end`, `caption`\n",
    "   - `image_jpeg` (bytes)\n",
    "   - `audio_wav` (bytes)\n",
    "\n",
    "Finally, we save the result to a **Parquet** file for use in your alignment notebooks.\n",
    "\n",
    "> ‚ö†Ô∏è Requirements: `yt-dlp`, `ffmpeg`, `opencv-python`, `pandas`, `pyarrow` must be installed in the environment where you run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7ad6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# Paths & High-Level Config\n",
    "# =============================================================\n",
    "from pathlib import Path\n",
    "\n",
    "# Root of your project (edit this if needed)\n",
    "ROOT_DIR = Path.cwd()\n",
    "\n",
    "# VALOR annotations JSON file (train split for example)\n",
    "# Example content (list of dicts):\n",
    "# [\n",
    "#   {\"video_id\": \"x-2Abohj8VY_30.000_40.000\", \"desc\": \"With the rumble, ...\"},\n",
    "#   {\"video_id\": \"ILE12hEW5Ck_30.000_40.000\", \"desc\": \"In one room, ...\"},\n",
    "#   ...\n",
    "# ]\n",
    "ANNOTATIONS_JSON = ROOT_DIR / \"data\" / \"valor_32k\" / \"desc_train.json\"  # <-- EDIT\n",
    "\n",
    "# Output Parquet path\n",
    "OUTPUT_PARQUET = ROOT_DIR / \"data\" / \"alignment_subsets\" / \"valor_32k_train_online.parquet\"\n",
    "OUTPUT_PARQUET.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Number of workers (processes) for parallel download + extraction\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "# Optional: cap number of samples for debugging (0 = use all)\n",
    "MAX_SAMPLES = 0\n",
    "\n",
    "# Image resize (width, height); set to 0 to keep original frame size\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "\n",
    "print(\"ROOT_DIR:\", ROOT_DIR)\n",
    "print(\"Annotations JSON:\", ANNOTATIONS_JSON)\n",
    "print(\"Output Parquet:\", OUTPUT_PARQUET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e89a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ffa1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# Imports & Environment Checks\n",
    "# =============================================================\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import tempfile\n",
    "import subprocess\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from typing import Any, Dict, Optional, Tuple\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"Python version:\", os.sys.version)\n",
    "\n",
    "# Check yt-dlp\n",
    "def _check_binary(name: str) -> bool:\n",
    "    from shutil import which\n",
    "    return which(name) is not None\n",
    "\n",
    "print(\"yt-dlp available:\", _check_binary(\"yt-dlp\"))\n",
    "print(\"ffmpeg available:\", _check_binary(\"ffmpeg\"))\n",
    "\n",
    "if not _check_binary(\"yt-dlp\"):\n",
    "    print(\"‚ö†Ô∏è yt-dlp not found in PATH. Please install it before running this notebook.\")\n",
    "if not _check_binary(\"ffmpeg\"):\n",
    "    print(\"‚ö†Ô∏è ffmpeg not found in PATH. Please install it before running this notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91958a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# Helper Functions: parse video_id, download clip, extract media\n",
    "# =============================================================\n",
    "def parse_video_id(video_id: str) -> Tuple[str, float, float]:\n",
    "    \"\"\"Split VALOR-style video_id into (yt_id, start, end).\n",
    "\n",
    "    Example: \"x-2Abohj8VY_30.000_40.000\" -> (\"x-2Abohj8VY\", 30.0, 40.0)\n",
    "    \"\"\"\n",
    "    parts = video_id.rsplit(\"_\", 2)\n",
    "    if len(parts) != 3:\n",
    "        raise ValueError(f\"Unexpected video_id format: {video_id}\")\n",
    "    yt_id, start_str, end_str = parts\n",
    "    return yt_id, float(start_str), float(end_str)\n",
    "\n",
    "\n",
    "def download_clip_to_temp(yt_id: str, start: float, end: float) -> Optional[Path]:\n",
    "    url = f\"https://www.youtube.com/watch?v={yt_id}\"\n",
    "    duration = max(0.0, end - start)\n",
    "    if duration <= 0:\n",
    "        print(f\"[ERROR] Invalid duration {duration} for {yt_id}\")\n",
    "        return None\n",
    "\n",
    "    tmp_dir = Path(tempfile.mkdtemp(prefix=\"valor_clip_\"))\n",
    "    out_path = tmp_dir / \"clip.mp4\"\n",
    "\n",
    "    section = f\"*{start}-{end}\"\n",
    "\n",
    "    cmd = [\n",
    "        \"yt-dlp\",\n",
    "        \"-f\", \"mp4\",\n",
    "        \"--download-sections\", section,\n",
    "        \"-o\", str(out_path),\n",
    "        \"--cookies-from-browser\", \"chrome\",\n",
    "        url,\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            cmd,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"[ERROR] yt-dlp failed for {yt_id}:\")\n",
    "        print(\"STDOUT:\\n\", e.stdout)\n",
    "        print(\"STDERR:\\n\", e.stderr)\n",
    "        return None\n",
    "\n",
    "    if not out_path.exists():\n",
    "        print(f\"[ERROR] Clip file not created for {yt_id}\")\n",
    "        return None\n",
    "\n",
    "    return out_path\n",
    "\n",
    "def extract_middle_frame(video_path: Path, resize: Optional[Tuple[int, int]] = None) -> Optional[bytes]:\n",
    "    \"\"\"Extract a middle frame from a video and return it as JPEG bytes.\"\"\"\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        return None\n",
    "\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if frame_count <= 0:\n",
    "        cap.release()\n",
    "        return None\n",
    "\n",
    "    middle_idx = frame_count // 2\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, middle_idx)\n",
    "    ok, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    if not ok or frame is None:\n",
    "        return None\n",
    "\n",
    "    if resize is not None:\n",
    "        w, h = resize\n",
    "        frame = cv2.resize(frame, (w, h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    success, buf = cv2.imencode(\".jpg\", frame)\n",
    "    if not success:\n",
    "        return None\n",
    "    return buf.tobytes()\n",
    "\n",
    "\n",
    "def extract_audio_wav(video_path: Path, sr: int = 16000) -> Optional[bytes]:\n",
    "    \"\"\"Extract mono WAV audio at the given sample rate from video.\n",
    "\n",
    "    Returns WAV bytes, or None on failure.\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\", str(video_path),\n",
    "        \"-vn\",              # no video\n",
    "        \"-ac\", \"1\",        # mono\n",
    "        \"-ar\", str(sr),     # sample rate\n",
    "        \"-f\", \"wav\",\n",
    "        \"-loglevel\", \"quiet\",\n",
    "        \"pipe:1\",           # write to stdout\n",
    "    ]\n",
    "    try:\n",
    "        proc = subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)\n",
    "        return proc.stdout\n",
    "    except subprocess.CalledProcessError:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd2fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# Worker Function for Multiprocessing\n",
    "# =============================================================\n",
    "import time\n",
    "\n",
    "def process_annotation(entry: Dict[str, Any], resize: Optional[Tuple[int, int]] = None) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Convert one VALOR entry ‚Üí Parquet row with logs.\n",
    "\n",
    "    Logs:\n",
    "      - Started processing\n",
    "      - Download success/failure\n",
    "      - Frame extraction success/failure\n",
    "      - Audio extraction success/failure\n",
    "      - Cleanup status\n",
    "      - Final success/failure\n",
    "    \"\"\"\n",
    "    video_id = entry.get(\"video_id\")\n",
    "    caption = entry.get(\"desc\") or entry.get(\"caption\") or \"\"\n",
    "    if not video_id:\n",
    "        print(f\"[WARN] Missing video_id in entry: {entry}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        yt_id, start, end = parse_video_id(video_id)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to parse video_id={video_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"\\n--- Processing {video_id} ---\")\n",
    "    print(f\"[INFO] yt_id={yt_id}  start={start}  end={end}\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    print(\"[INFO] Downloading clip segment...\")\n",
    "    clip_path = download_clip_to_temp(yt_id, start, end)\n",
    "    if clip_path is None:\n",
    "        print(f\"[ERROR] Failed to download segment for {video_id}\")\n",
    "        return None\n",
    "    print(f\"[OK] Downloaded to: {clip_path}\")\n",
    "\n",
    "    # Extract frame + audio\n",
    "    try:\n",
    "        print(\"[INFO] Extracting middle frame...\")\n",
    "        frame_bytes = extract_middle_frame(clip_path, resize=resize)\n",
    "        if frame_bytes is None:\n",
    "            print(\"[ERROR] Failed to extract middle frame\")\n",
    "            raise RuntimeError(\"frame extraction failure\")\n",
    "        print(\"[OK] Frame extracted\")\n",
    "\n",
    "        print(\"[INFO] Extracting audio wav...\")\n",
    "        audio_bytes = extract_audio_wav(clip_path, sr=16000)\n",
    "        if audio_bytes is None:\n",
    "            print(\"[ERROR] Failed to extract audio\")\n",
    "            raise RuntimeError(\"audio extraction failure\")\n",
    "        print(f\"[OK] Audio extracted: {len(audio_bytes)} bytes\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Extraction failed for {video_id}: {e}\")\n",
    "        # Cleanup\n",
    "        try:\n",
    "            tmp_dir = clip_path.parent\n",
    "            if clip_path.exists(): clip_path.unlink()\n",
    "            tmp_dir.rmdir()\n",
    "        except:\n",
    "            pass\n",
    "        return None\n",
    "\n",
    "    # Cleanup\n",
    "    print(\"[INFO] Cleaning up temporary files...\")\n",
    "    try:\n",
    "        tmp_dir = clip_path.parent\n",
    "        if clip_path.exists():\n",
    "            clip_path.unlink()\n",
    "        tmp_dir.rmdir()\n",
    "        print(\"[OK] Cleanup complete\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Cleanup issue: {e}\")\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(f\"[SUCCESS] {video_id} processed in {dt:.2f}s\")\n",
    "\n",
    "    return {\n",
    "        \"video_id\": video_id,\n",
    "        \"yt_id\": yt_id,\n",
    "        \"start\": start,\n",
    "        \"end\": end,\n",
    "        \"caption\": caption,\n",
    "        \"image_jpeg\": frame_bytes,\n",
    "        \"audio_wav\": audio_bytes,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae58545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# Build VALOR-32K Parquet (Online Download)\n",
    "# =============================================================\n",
    "assert ANNOTATIONS_JSON.is_file(), f\"Annotations JSON not found: {ANNOTATIONS_JSON}\"\n",
    "\n",
    "with ANNOTATIONS_JSON.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "if not isinstance(annotations, list):\n",
    "    raise ValueError(\"Annotations JSON must be a list of dicts.\")\n",
    "\n",
    "if MAX_SAMPLES and MAX_SAMPLES > 0:\n",
    "    annotations = annotations[:MAX_SAMPLES]\n",
    "\n",
    "print(f\"Total annotations to process: {len(annotations)}\")\n",
    "\n",
    "resize = (IMG_WIDTH, IMG_HEIGHT) if IMG_WIDTH > 0 and IMG_HEIGHT > 0 else None\n",
    "\n",
    "results = []\n",
    "num_failed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c0b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pool as ThreadPool  # <‚Äî threads, not processes\n",
    "\n",
    "if NUM_WORKERS <= 1:\n",
    "    # Single-process\n",
    "    for entry in tqdm(annotations, desc=\"Processing VALOR entries (single process)\"):\n",
    "        row = process_annotation(entry, resize=resize)\n",
    "        if row is None:\n",
    "            num_failed += 1\n",
    "        else:\n",
    "            results.append(row)\n",
    "else:\n",
    "    # Multi-threaded (better for Jupyter + macOS)\n",
    "    worker = partial(process_annotation, resize=resize)\n",
    "    with ThreadPool(processes=NUM_WORKERS) as pool:\n",
    "        for row in tqdm(\n",
    "            pool.imap_unordered(worker, annotations, chunksize=4),\n",
    "            total=len(annotations),\n",
    "            desc=\"Processing VALOR entries (threads)\"\n",
    "        ):\n",
    "            if row is None:\n",
    "                num_failed += 1\n",
    "            else:\n",
    "                results.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82dd6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n‚úÖ Finished processing annotations.\")\n",
    "print(f\"   Successful rows: {len(results)}\")\n",
    "print(f\"   Failed/missed  : {num_failed}\")\n",
    "\n",
    "if not results:\n",
    "    print(\"‚ö†Ô∏è No valid rows collected. Skipping Parquet save.\")\n",
    "else:\n",
    "    df = pd.DataFrame(results)\n",
    "    print(df.head())\n",
    "    df.to_parquet(OUTPUT_PARQUET, index=False)\n",
    "    print(f\"\\nüíæ Saved VALOR-32K image+audio+caption parquet to: {OUTPUT_PARQUET}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edge_glass_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

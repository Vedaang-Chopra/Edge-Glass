{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b58e5062",
   "metadata": {},
   "source": [
    "# Build Clotho Development Parquet\n",
    "\n",
    "This notebook converts the **Clotho v2.x development split** that you downloaded\n",
    "from Zenodo into a single **Parquet** file with:\n",
    "\n",
    "- `audio`: a Hugging Face `Audio` column (waveform + sampling rate)\n",
    "- `caption`: one caption per row\n",
    "- `file_name`: original audio file name\n",
    "- `caption_idx`: which caption (1‚Äì5)\n",
    "- `split`: `\"development\"`\n",
    "\n",
    "Edit the paths in the config cell below if needed, then run all cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf72423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset, Audio\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Configuration\n",
    "# ------------------------------------------------------------------\n",
    "# Adjust these paths to match your repo layout.\n",
    "\n",
    "# Directory that contains the *audio files* for the development split.\n",
    "# From your screenshot, this is likely: v2_code_base/data/clotho/development\n",
    "CLOTHO_DEV_AUDIO_DIR = Path.cwd() / \"data\" / \"clotho\" / \"development\"\n",
    "\n",
    "# Path to the *captions CSV* for development.\n",
    "# From your screenshot, this looked like: v2_code_base/data/clotho_captions_development.csv\n",
    "CLOTHO_DEV_CAPTIONS_CSV = Path.cwd() / \"data\" / \"clotho_captions_development.csv\"\n",
    "# Output Parquet path (will be created if missing)\n",
    "OUTPUT_PARQUET_PATH = Path.cwd() / \"data\" / \"alignment_offline\" / \"clotho_development.parquet\"\n",
    "OUTPUT_PARQUET_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Clotho audio sampling rate (per paper: 44.1 kHz)\n",
    "TARGET_SR = 44_100\n",
    "\n",
    "print(\"Audio dir :\", CLOTHO_DEV_AUDIO_DIR.resolve())\n",
    "print(\"Captions  :\", CLOTHO_DEV_CAPTIONS_CSV.resolve())\n",
    "print(\"Output    :\", OUTPUT_PARQUET_PATH.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1395f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clotho_dev_parquet(\n",
    "    audio_dir: Path,\n",
    "    captions_csv: Path,\n",
    "    output_path: Path,\n",
    "    target_sr: int = TARGET_SR,\n",
    ") -> Path:\n",
    "    \"\"\"Build a Parquet file for the Clotho *development* split.\n",
    "\n",
    "    One row per (audio file, caption), with columns:\n",
    "      - audio      : HF Audio column\n",
    "      - caption    : text\n",
    "      - file_name  : original wav file name\n",
    "      - caption_idx: which caption (1..5)\n",
    "      - split      : 'development'\n",
    "    \"\"\"\n",
    "    audio_dir = Path(audio_dir)\n",
    "    captions_csv = Path(captions_csv)\n",
    "    output_path = Path(output_path)\n",
    "\n",
    "    assert audio_dir.exists(), f\"Audio directory not found: {audio_dir}\"\n",
    "    assert captions_csv.exists(), f\"Captions CSV not found: {captions_csv}\"\n",
    "\n",
    "    if output_path.exists():\n",
    "        print(f\"üìÇ Parquet already exists, skipping build: {output_path}\")\n",
    "        return output_path\n",
    "\n",
    "    print(f\"\\nüì• Loading captions from: {captions_csv}\")\n",
    "    df = pd.read_csv(captions_csv, header=0)\n",
    "\n",
    "    # Expect columns like 'File_name', 'Caption_1', ..., 'Caption_5'\n",
    "    if \"file_name\" not in df.columns:\n",
    "        raise ValueError(f\"Expected 'file_name' column in {captions_csv}, got {df.columns.tolist()}\")\n",
    "\n",
    "    caption_cols = [c for c in df.columns if c.lower().startswith(\"caption\")]\n",
    "    if not caption_cols:\n",
    "        raise ValueError(f\"No caption columns found in {captions_csv} (columns={df.columns.tolist()})\")\n",
    "\n",
    "    print(f\"   Found caption columns: {caption_cols}\")\n",
    "\n",
    "    # Convert to long format: one row per (file_name, caption)\n",
    "    df_long = df.melt(\n",
    "        id_vars=[\"file_name\"],\n",
    "        value_vars=caption_cols,\n",
    "        var_name=\"caption_idx\",\n",
    "        value_name=\"caption\",\n",
    "    )\n",
    "\n",
    "    # Clean up caption index: 'Caption_1' -> 1\n",
    "    df_long[\"caption_idx\"] = (\n",
    "        df_long[\"caption_idx\"]\n",
    "        .astype(str)\n",
    "        .str.extract(r\"(\\d+)$\")\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "    # Drop missing captions\n",
    "    df_long = df_long.dropna(subset=[\"caption\"])\n",
    "    df_long[\"caption\"] = df_long[\"caption\"].astype(str).str.strip()\n",
    "\n",
    "    # Build full audio path\n",
    "    df_long[\"file_name\"] = df_long[\"file_name\"].astype(str)\n",
    "    df_long[\"audio_path\"] = df_long[\"file_name\"].apply(lambda fn: str(audio_dir / fn))\n",
    "    df_long[\"split\"] = \"development\"\n",
    "\n",
    "    # Filter rows where audio actually exists\n",
    "    exists_mask = df_long[\"audio_path\"].apply(lambda p: Path(p).exists())\n",
    "    missing = (~exists_mask).sum()\n",
    "    if missing > 0:\n",
    "        print(f\"   ‚ö†Ô∏è {missing} rows refer to missing audio files ‚Äì dropping them.\")\n",
    "    df_long = df_long[exists_mask]\n",
    "\n",
    "    print(f\"   Final rows in long-form table: {len(df_long):,}\")\n",
    "\n",
    "    # Build HF Dataset and cast audio\n",
    "    print(\"üß± Creating HuggingFace Dataset...\")\n",
    "    ds = Dataset.from_pandas(df_long[[\"file_name\", \"caption\", \"caption_idx\", \"audio_path\", \"split\"]],\n",
    "                             preserve_index=False)\n",
    "\n",
    "    print(\"üéß Casting 'audio_path' to Audio column (lazy loading from wav files)...\")\n",
    "    ds = ds.cast_column(\"audio_path\", Audio(sampling_rate=target_sr))\n",
    "    ds = ds.rename_column(\"audio_path\", \"audio\")\n",
    "\n",
    "    print(f\"üíæ Saving Parquet to: {output_path}\")\n",
    "    ds.to_parquet(str(output_path))\n",
    "    print(\"‚úÖ Done.\")\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7634307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Run builder + quick sanity check\n",
    "# ------------------------------------------------------------------\n",
    "parquet_path = build_clotho_dev_parquet(\n",
    "    audio_dir=CLOTHO_DEV_AUDIO_DIR,\n",
    "    captions_csv=CLOTHO_DEV_CAPTIONS_CSV,\n",
    "    output_path=OUTPUT_PARQUET_PATH,\n",
    ")\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"\\nüîé Loading back Parquet for sanity check...\")\n",
    "ds = load_dataset(\"parquet\", data_files={\"train\": str(parquet_path)})[\"train\"]\n",
    "print(ds)\n",
    "print(\"Columns:\", ds.column_names)\n",
    "\n",
    "example = ds[0]\n",
    "print(\"\\nExample row:\")\n",
    "print(\"  file_name  :\", example[\"file_name\"])\n",
    "print(\"  caption    :\", example[\"caption\"])\n",
    "print(\"  caption_idx:\", example[\"caption_idx\"])\n",
    "print(\"  audio sr   :\", example[\"audio\"][\"sampling_rate\"])\n",
    "print(\"  audio shape:\", example[\"audio\"][\"array\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf9010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edge_glass_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

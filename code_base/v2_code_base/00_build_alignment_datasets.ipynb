{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b8f6584",
   "metadata": {},
   "source": [
    "\n",
    "# 00 ‚Äî Build Local Alignment Datasets (PixMo-Cap & MusicCaps)\n",
    "\n",
    "This notebook creates small **local Parquet subsets** of the online Hugging Face datasets:\n",
    "\n",
    "- **Vision‚ÄìText:** `allenai/pixmo-cap`\n",
    "- **Audio‚ÄìText:** `google/MusicCaps`\n",
    "\n",
    "It will:\n",
    "\n",
    "1. Download each dataset (once),  \n",
    "2. Select **N samples** for alignment experiments,  \n",
    "3. Save them as **`.parquet`** files under a local `data/` folder,  \n",
    "4. (Optionally) show how to load them back via `datasets.load_dataset(\"parquet\", ...)`.\n",
    "\n",
    "All your alignment / training notebooks can then read from these local Parquet files instead of re-downloading from the hub.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "994b23b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /storage/ice1/1/0/vchopra37/projects/edge_glass/code_base/v2_code_base\n",
      "Saving PixMo-Cap subset to: /storage/ice1/1/0/vchopra37/projects/edge_glass/code_base/v2_code_base/data/alignment_subsets/pixmocap_train_subset_50000.parquet\n",
      "Saving MusicCaps subset to: /storage/ice1/1/0/vchopra37/projects/edge_glass/code_base/v2_code_base/data/alignment_subsets/musiccaps_train_subset_25000.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Standard imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Optional: pandas only for quick inspection (not required for saving)\n",
    "import pandas as pd\n",
    "\n",
    "# Base directory where this notebook lives\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"alignment_subsets\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- CONFIG ----\n",
    "# Number of samples to keep from each dataset\n",
    "N_PIXMO_SAMPLES = 50_000   # adjust based on your GPU/RAM\n",
    "N_MUSICCAPS_SAMPLES = 25_000\n",
    "\n",
    "# Output Parquet paths\n",
    "PIXMO_PARQUET_PATH = DATA_DIR / f\"pixmocap_train_subset_{N_PIXMO_SAMPLES}.parquet\"\n",
    "MUSICCAPS_PARQUET_PATH = DATA_DIR / f\"musiccaps_train_subset_{N_MUSICCAPS_SAMPLES}.parquet\"\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Saving PixMo-Cap subset to: {PIXMO_PARQUET_PATH}\")\n",
    "print(f\"Saving MusicCaps subset to: {MUSICCAPS_PARQUET_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "341ff589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataset_builders.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile dataset_builders.py\n",
    "\"\"\"\n",
    "dataset_builders.py\n",
    "\n",
    "Utility functions to create local Parquet subsets of the PixMo-Cap\n",
    "and MusicCaps datasets for alignment experiments.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "\n",
    "def build_pixmocap_parquet(\n",
    "    output_path: Path,\n",
    "    split: str = \"train\",\n",
    "    max_samples: Optional[int] = None,\n",
    "    shuffle_seed: int = 42,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Download a subset of PixMo-Cap and save it as a Parquet file.\n",
    "\n",
    "    The resulting Parquet file will keep all original columns, including:\n",
    "    - `image_url`: used by InMemoryImageTextDataset\n",
    "    - `caption`   : used as text field\n",
    "\n",
    "    Args:\n",
    "        output_path: Where to save the Parquet file.\n",
    "        split: HF split to use (default: \"train\").\n",
    "        max_samples: If provided, randomly select at most this many samples.\n",
    "        shuffle_seed: Seed for shuffling before subsetting.\n",
    "    \"\"\"\n",
    "    output_path = Path(output_path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"üì• Loading PixMo-Cap split='{split}' from Hugging Face...\")\n",
    "    ds = load_dataset(\"allenai/pixmo-cap\", split=split)\n",
    "\n",
    "    print(f\"   Total available samples: {len(ds):,}\")\n",
    "    if max_samples is not None and max_samples < len(ds):\n",
    "        print(f\"   Shuffling and selecting first {max_samples:,} samples (seed={shuffle_seed})...\")\n",
    "        ds = ds.shuffle(seed=shuffle_seed).select(range(max_samples))\n",
    "    else:\n",
    "        print(\"   Using full split (no subsetting).\")\n",
    "\n",
    "\n",
    "    print(f\"üíæ Saving subset to Parquet: {output_path}\")\n",
    "    ds.to_parquet(str(output_path))\n",
    "    print(\"‚úÖ Done! PixMo-Cap subset saved.\")\n",
    "\n",
    "\n",
    "def build_musiccaps_parquet(\n",
    "    output_path: Path,\n",
    "    split: str = \"train\",\n",
    "    max_samples: Optional[int] = None,\n",
    "    shuffle_seed: int = 42,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Download a subset of MusicCaps and save it as a Parquet file.\n",
    "\n",
    "    The resulting Parquet file will keep all original columns, including:\n",
    "    - `audio`   : HF Audio column (waveforms + metadata)\n",
    "    - `caption` : used as text field\n",
    "\n",
    "    Args:\n",
    "        output_path: Where to save the Parquet file.\n",
    "        split: HF split to use (default: \"train\").\n",
    "        max_samples: If provided, randomly select at most this many samples.\n",
    "        shuffle_seed: Seed for shuffling before subsetting.\n",
    "    \"\"\"\n",
    "    output_path = Path(output_path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"üì• Loading MusicCaps split='{split}' from Hugging Face...\")\n",
    "    ds = load_dataset(\"google/MusicCaps\", split=split)\n",
    "\n",
    "    print(f\"   Total available samples: {len(ds):,}\")\n",
    "    if max_samples is not None and max_samples < len(ds):\n",
    "        print(f\"   Shuffling and selecting first {max_samples:,} samples (seed={shuffle_seed})...\")\n",
    "        ds = ds.shuffle(seed=shuffle_seed).select(range(max_samples))\n",
    "    else:\n",
    "        print(\"   Using full split (no subsetting).\")\n",
    "\n",
    "\n",
    "    print(f\"üíæ Saving subset to Parquet: {output_path}\")\n",
    "    ds.to_parquet(str(output_path))\n",
    "    print(\"‚úÖ Done! MusicCaps subset saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1c73783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f69a435",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _validate_pixmo_index(args):\n",
    "    \"\"\"\n",
    "    Worker function for multiprocessing validation of PixMo-Cap rows.\n",
    "\n",
    "    Args:\n",
    "        args: tuple (idx, dataset)\n",
    "\n",
    "    Returns:\n",
    "        None if row is OK,\n",
    "        or (idx, missing_keys) if some fields are missing.\n",
    "    \"\"\"\n",
    "    idx, ds = args\n",
    "    row = ds[idx]\n",
    "\n",
    "    missing = []\n",
    "    if \"image_url\" not in row:\n",
    "        missing.append(\"image_url\")\n",
    "    if \"caption\" not in row:\n",
    "        missing.append(\"caption\")\n",
    "\n",
    "    if missing:\n",
    "        return idx, missing\n",
    "    return None\n",
    "\n",
    "\n",
    "def _log_sample_preview(ds, n_preview=3):\n",
    "    \"\"\"Print the first N rows for sanity.\"\"\"\n",
    "    print(\"\\nüîç Sample preview:\")\n",
    "    for i in range(min(n_preview, len(ds))):\n",
    "        print(f\"  ‚Ä¢ [{i}] { {k: str(ds[i][k])[:80] for k in ds.column_names} }\")\n",
    "    print()\n",
    "\n",
    "\n",
    "def _log_progress(i, total, dataset_name, step=5000):\n",
    "    \"\"\"Log every fixed interval.\"\"\"\n",
    "    if i % step == 0:\n",
    "        pct = (i / total) * 100\n",
    "        print(f\"[{dataset_name}] Processed {i:,}/{total:,} ({pct:.2f}%)...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702de946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#                               PIXMO‚ÄìCAP BUILDER\n",
    "# -----------------------------------------------------------------------------\n",
    "def build_pixmocap_parquet(\n",
    "    output_path: Path,\n",
    "    split: str = \"train\",\n",
    "    max_samples: Optional[int] = None,\n",
    "    shuffle_seed: int = 42,\n",
    ") -> None:\n",
    "\n",
    "    output_path = Path(output_path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"\\nüì• Loading PixMo-Cap split='{split}' from Hugging Face...\")\n",
    "    ds = load_dataset(\"allenai/pixmo-cap\", split=split)\n",
    "\n",
    "    total = len(ds)\n",
    "    print(f\"   Total available samples: {total:,}\")\n",
    "\n",
    "    # Preview\n",
    "    _log_sample_preview(ds)\n",
    "\n",
    "    # Subset\n",
    "    if max_samples is not None and max_samples < total:\n",
    "        print(f\"   Shuffling + selecting {max_samples:,} samples (seed={shuffle_seed})...\")\n",
    "        ds = ds.shuffle(seed=shuffle_seed).select(range(max_samples))\n",
    "    else:\n",
    "        print(\"   Using full split.\")\n",
    "\n",
    "    print(f\"   Final subset size: {len(ds):,}\")\n",
    "\n",
    "    # ----------------- MULTIPROCESSING VALIDATION -----------------\n",
    "    print(\"\\nüìù Scanning dataset for basic validation (multiprocessing)...\")\n",
    "\n",
    "    num_workers = min(cpu_count(), 8)  # tune this if needed\n",
    "    print(f\"   Using {num_workers} worker processes\")\n",
    "\n",
    "    missing_count = 0\n",
    "    total_rows = len(ds)\n",
    "\n",
    "    # Generator of tasks: each worker gets (idx, ds)\n",
    "    # ds will be copied to each worker process once (acceptable for moderate sizes)\n",
    "    tasks = ((i, ds) for i in range(total_rows))\n",
    "\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        for j, result in enumerate(\n",
    "            tqdm(\n",
    "                pool.imap_unordered(_validate_pixmo_index, tasks, chunksize=512),\n",
    "                total=total_rows,\n",
    "                desc=\"Validating PixMo samples (mp)\",\n",
    "            )\n",
    "        ):\n",
    "            # Progress log (every 10k rows)\n",
    "            if j % 10_000 == 0 and j > 0:\n",
    "                _log_progress(j, total_rows, \"PixMo-Cap\", step=10_000)\n",
    "\n",
    "            # If something is missing, result is (idx, missing_keys)\n",
    "            if result is not None:\n",
    "                idx, missing_keys = result\n",
    "                missing_count += 1\n",
    "                print(f\"‚ö†Ô∏è Missing {missing_keys} at index {idx}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Validation complete. Rows with missing fields: {missing_count:,}/{total_rows:,}\")\n",
    "\n",
    "    # ----------------- SAVE TO PARQUET -----------------\n",
    "    print(f\"\\nüíæ Saving subset to Parquet: {output_path}\")\n",
    "    ds.to_parquet(str(output_path))\n",
    "\n",
    "    print(\"‚úÖ Done! PixMo-Cap subset saved.\")\n",
    "    print(\"üìå File:\", output_path)\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2690ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Building PixMo-Cap subset ===\n",
      "\n",
      "üì• Loading PixMo-Cap split='train' from Hugging Face...\n",
      "   Total available samples: 717,042\n",
      "\n",
      "üîç Sample preview:\n",
      "  ‚Ä¢ [0] {'image_url': 'https://pixmo.s3.us-west-2.amazonaws.com/birds/1491.png', 'caption': 'This photograph depicts a striking black bird, possibly a grackle or similar spe', 'transcripts': '[\"This is a picture of a long black bird with a lot of iridescent accents. It lo'}\n",
      "  ‚Ä¢ [1] {'image_url': 'https://i.pinimg.com/736x/a8/d4/30/a8d430e8b24249577d09ea0a9c4bec54.jpg', 'caption': 'This nighttime image captures a dynamic point of view from a motorcycle rider on', 'transcripts': '[\"This image is outside at night. You can just see the part of the motorcycle th'}\n",
      "  ‚Ä¢ [2] {'image_url': 'https://i.redd.it/tujlim4fvo2d1.png', 'caption': 'The image showcases a dynamic, animated scene featuring four distinct characters', 'transcripts': '[\"This is a picture of, I think, four characters, animated characters. And the f'}\n",
      "\n",
      "   Shuffling + selecting 50,000 samples (seed=42)...\n",
      "   Final subset size: 50,000\n",
      "\n",
      "üìù Scanning dataset for basic validation (multiprocessing)...\n",
      "   Using 8 worker processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating PixMo samples (mp):  20%|‚ñà‚ñâ        | 9871/50000 [00:13<00:26, 1488.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PixMo-Cap] Processed 10,000/50,000 (20.00%)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating PixMo samples (mp):  41%|‚ñà‚ñà‚ñà‚ñà      | 20481/50000 [00:20<00:14, 2007.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PixMo-Cap] Processed 20,000/50,000 (40.00%)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating PixMo samples (mp):  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 29697/50000 [00:24<00:06, 3049.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PixMo-Cap] Processed 30,000/50,000 (60.00%)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating PixMo samples (mp):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 39937/50000 [00:29<00:05, 1912.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PixMo-Cap] Processed 40,000/50,000 (80.00%)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating PixMo samples (mp): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50000/50000 [00:32<00:00, 1515.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Validation complete. Rows with missing fields: 0/50,000\n",
      "\n",
      "üíæ Saving subset to Parquet: /storage/ice1/1/0/vchopra37/projects/edge_glass/code_base/v2_code_base/data/alignment_subsets/pixmocap_train_subset_50000.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c80a0dd64ba469498fb44ecd675115e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done! PixMo-Cap subset saved.\n",
      "üìå File: /storage/ice1/1/0/vchopra37/projects/edge_glass/code_base/v2_code_base/data/alignment_subsets/pixmocap_train_subset_50000.parquet\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Building PixMo-Cap subset ===\")\n",
    "build_pixmocap_parquet(\n",
    "    output_path=PIXMO_PARQUET_PATH,\n",
    "    split=\"train\",\n",
    "    max_samples=N_PIXMO_SAMPLES,\n",
    "    shuffle_seed=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9635c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "#                           MUSICCAPS BUILDER\n",
    "# -----------------------------------------------------------------------------\n",
    "def build_musiccaps_parquet(\n",
    "    output_path: Path,\n",
    "    split: str = \"train\",\n",
    "    max_samples: Optional[int] = None,\n",
    "    shuffle_seed: int = 42,\n",
    ") -> None:\n",
    "\n",
    "    output_path = Path(output_path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"\\nüì• Loading MusicCaps split='{split}' from Hugging Face...\")\n",
    "    ds = load_dataset(\"google/MusicCaps\", split=split)\n",
    "\n",
    "    total = len(ds)\n",
    "    print(f\"   Total available samples: {total:,}\")\n",
    "\n",
    "    # Preview\n",
    "    _log_sample_preview(ds)\n",
    "\n",
    "    # Subset\n",
    "    if max_samples is not None and max_samples < total:\n",
    "        print(f\"   Shuffling + selecting {max_samples:,} samples (seed={shuffle_seed})...\")\n",
    "        ds = ds.shuffle(seed=shuffle_seed).select(range(max_samples))\n",
    "    else:\n",
    "        print(\"   Using full split.\")\n",
    "\n",
    "    # Log progress with safe step interval\n",
    "    print(\"\\nüìù Scanning dataset for audio & caption fields...\")\n",
    "    for i in tqdm(range(len(ds)), desc=\"Validating MusicCaps samples\"):\n",
    "        _log_progress(i, len(ds), \"MusicCaps\", step=10_000)\n",
    "\n",
    "        row = ds[i]\n",
    "        if \"audio\" not in row:\n",
    "            print(f\"‚ö†Ô∏è Missing 'audio' column in index {i}\")\n",
    "        if \"caption\" not in row:\n",
    "            print(f\"‚ö†Ô∏è Missing 'caption' column in index {i}\")\n",
    "\n",
    "    print(f\"\\nüíæ Saving subset to Parquet: {output_path}\")\n",
    "    ds.to_parquet(str(output_path))\n",
    "\n",
    "    print(\"‚úÖ Done! MusicCaps subset saved.\")\n",
    "    print(\"üìå File:\", output_path)\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd50e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"\\n=== Building MusicCaps subset ===\")\n",
    "try:\n",
    "    build_musiccaps_parquet(\n",
    "        output_path=MUSICCAPS_PARQUET_PATH,\n",
    "        split=\"train\",\n",
    "        max_samples=N_MUSICCAPS_SAMPLES,\n",
    "        shuffle_seed=42,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è MusicCaps build failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37d6d69",
   "metadata": {},
   "source": [
    "\n",
    "## Quick sanity check (optional)\n",
    "\n",
    "The following cell shows how to load the saved Parquet subsets back using `datasets.load_dataset`,\n",
    "and how to plug them into your existing in-memory datasets for alignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87c3389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Verifying PixMo-Cap Parquet subset ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b45c28217d4e358af6c8d66d36b1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image_url', 'caption', 'transcripts'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n",
      "  Columns: ['image_url', 'caption', 'transcripts']\n",
      "  Example row: {'image_url': 'https://objaverse-renders.s3.us-west-2.amazonaws.com/robustness/drawer/89d1fcd0ec0f486c8fc3e5d811a1fe5c-000.png', 'caption': \"This digital graphic features a modern, square wooden chest of drawers positioned at the center of the image, which is set against a plain white background. The chest's design is minimalistic with clean lines, highlighted by a slight shadow cast from the top onto the drawers and side, adding depth to the illustration. The chest boasts long, straight white drawer pulls that complement its sleek appearance. A vertical wood grain pattern is evident on the drawers, further emphasizing the natural texture and elegance of the piece. The outer edges of the graphic appear slightly serrated, creating an imperfect, textured finish around the silhouette of the object.\", 'transcripts': ['This image is a digital graphic object. It is sitting free standing in the center. There is no background, it is white. This is a small chest of drawers. It is a wooden chest of drawers. It is square and modern. The right hand side that meets the right hand edge is a center line in the very center of the image. And there is a slight shadow coming from the top of the dresser onto the drawer and the side of the dresser. The dressers have a long, straight drawer pull. They are white. There is some grain that is shown in the wood moving in the direction of the wood and the drawers. It is a vertical grain. The outside of the image looks slightly serrated. It is not perfectly solid line throughout the outer portion of the object.']}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "print(\"\\n=== Verifying PixMo-Cap Parquet subset ===\")\n",
    "pixmo_local = load_dataset(\n",
    "    \"parquet\",\n",
    "    data_files={\"train\": str(PIXMO_PARQUET_PATH)},\n",
    ")\n",
    "print(pixmo_local)\n",
    "print(\"  Columns:\", pixmo_local[\"train\"].column_names)\n",
    "print(\"  Example row:\", pixmo_local[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b7f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"\\n=== Verifying MusicCaps Parquet subset (if available) ===\")\n",
    "if MUSICCAPS_PARQUET_PATH.exists():\n",
    "    musiccaps_local = load_dataset(\n",
    "        \"parquet\",\n",
    "        data_files={\"train\": str(MUSICCAPS_PARQUET_PATH)},\n",
    "    )\n",
    "    print(musiccaps_local)\n",
    "    print(\"  Columns:\", musiccaps_local[\"train\"].column_names)\n",
    "    print(\"  Example row:\", musiccaps_local[\"train\"][0])\n",
    "else:\n",
    "    print(\"  Skipped: MusicCaps Parquet file not found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edge_glass_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

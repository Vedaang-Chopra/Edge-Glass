{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e15f1686",
   "metadata": {},
   "source": [
    "\n",
    "# MusicCaps ‚Üí Waveform Parquet Builder (Mac / Local)\n",
    "\n",
    "This notebook downloads the **Google MusicCaps** dataset audio from YouTube,\n",
    "extracts the specified `[start_s, end_s]` segment for each clip, and saves\n",
    "everything into a **single Parquet file** with:\n",
    "\n",
    "- `audio.array` ‚Äì the waveform as a float32 numpy array\n",
    "- `audio.sampling_rate` ‚Äì sampling rate (Hz)\n",
    "- all original MusicCaps metadata (caption, ytid, etc.)\n",
    "\n",
    "You run this **once** on your Mac, then copy the the Parquet to PACE and train\n",
    "purely offline from that file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac39d24",
   "metadata": {},
   "source": [
    "## 1. Install dependencies (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "500f65a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If needed, install these in your Mac environment (uncomment as needed):\n",
    "# ! uv pip install yt-dlp soundfile datasets\n",
    "\n",
    "# On macOS, make sure ffmpeg is installed, e.g.:\n",
    "#   brew install ffmpeg\n",
    "#\n",
    "# And confirm:\n",
    "# ! ffmpeg -version | head -n 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced580a2",
   "metadata": {},
   "source": [
    "## 2. Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92fc39fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/vedaangchopra/all_data/complete_technical_work/all_projects_implemented/Edge Assistant/code_base/v2_code_base\n",
      "Output Parquet: /Users/vedaangchopra/all_data/complete_technical_work/all_projects_implemented/Edge Assistant/code_base/v2_code_base/data/musiccaps_waveform.parquet\n",
      "Tmp audio dir: /Users/vedaangchopra/all_data/complete_technical_work/all_projects_implemented/Edge Assistant/code_base/v2_code_base/data/musiccaps_tmp\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from datasets import load_dataset\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "# ---- PATHS ----\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MUSICC_PARQUET_PATH = DATA_DIR / \"musiccaps_waveform.parquet\"\n",
    "TMP_AUDIO_DIR = DATA_DIR / \"musiccaps_tmp\"\n",
    "\n",
    "# ---- CONFIG ----\n",
    "MAX_SAMPLES = None   # e.g. 5000 for subset, or None for full 5521\n",
    "NUM_WORKERS = 32    # adjust based on your Mac cores\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Output Parquet: {MUSICC_PARQUET_PATH}\")\n",
    "print(f\"Tmp audio dir: {TMP_AUDIO_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d32194",
   "metadata": {},
   "source": [
    "## 3. Helper ‚Äì download clip and slice with ffmpeg via yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af2e8123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _download_musiccaps_clip_to_array(\n",
    "    ytid: str,\n",
    "    start_s: float,\n",
    "    end_s: float,\n",
    "    tmp_dir: Path,\n",
    ") -> tuple[np.ndarray | None, int | None, str]:\n",
    "    \"\"\"\n",
    "    Download the [start_s, end_s] segment for a MusicCaps clip as WAV using yt-dlp,\n",
    "    load into memory, delete the temp file, and return:\n",
    "        (waveform, sampling_rate, fail_reason)\n",
    "\n",
    "    - On success: (np.ndarray, int, \"ok\")\n",
    "    - On failure: (None, None, <short_reason_string>)\n",
    "    \"\"\"\n",
    "    tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = tmp_dir / f\"{ytid}.wav\"\n",
    "\n",
    "    url = f\"https://www.youtube.com/watch?v={ytid}\"\n",
    "\n",
    "    cmd = f\"\"\"\n",
    "        yt-dlp --quiet --no-warnings \\\n",
    "        -f \"bestaudio/best\" \\\n",
    "        --cookies-from-browser chrome \\\n",
    "        -x --audio-format wav \\\n",
    "        -o \"{tmp_path}\" \\\n",
    "        --download-sections \"*{start_s}-{end_s}\" \\\n",
    "        \"{url}\"\n",
    "    \"\"\".strip()\n",
    "\n",
    "    try:\n",
    "        # 120s timeout per clip to avoid hanging workers\n",
    "        subprocess.check_output(\n",
    "            cmd,\n",
    "            shell=True,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            timeout=120,\n",
    "        )\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"[yt-dlp TIMEOUT] ytid={ytid}\")\n",
    "        if tmp_path.exists():\n",
    "            tmp_path.unlink(missing_ok=True)\n",
    "        return None, None, \"timeout\"\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        # Inspect yt-dlp error to categorize\n",
    "        reason = \"yt_dlp_error\"\n",
    "        try:\n",
    "            msg = e.output.decode(\"utf-8\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            msg = str(e)\n",
    "\n",
    "        if \"Video unavailable\" in msg and \"terminated\" in msg:\n",
    "            reason = \"video_terminated\"\n",
    "        elif \"Video unavailable\" in msg and \"private\" in msg:\n",
    "            reason = \"private\"\n",
    "        elif \"Requested format is not available\" in msg:\n",
    "            reason = \"format_unavailable\"\n",
    "\n",
    "        print(f\"[yt-dlp FAIL] ytid={ytid} | reason={reason}\")\n",
    "        print(\"---- yt-dlp output (truncated) ----\")\n",
    "        print(msg[:300])\n",
    "        print(\"---- end ----\")\n",
    "\n",
    "        if tmp_path.exists():\n",
    "            tmp_path.unlink(missing_ok=True)\n",
    "        return None, None, reason\n",
    "\n",
    "    if not tmp_path.exists():\n",
    "        return None, None, \"no_output_file\"\n",
    "\n",
    "    try:\n",
    "        waveform, sr = sf.read(tmp_path, always_2d=False)\n",
    "        waveform = np.asarray(waveform, dtype=np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"[sf.read FAIL] ytid={ytid} | err={e}\")\n",
    "        tmp_path.unlink(missing_ok=True)\n",
    "        return None, None, \"sf_read_error\"\n",
    "\n",
    "    # Clean up file immediately\n",
    "    tmp_path.unlink(missing_ok=True)\n",
    "\n",
    "    return waveform, sr, \"ok\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed959d23",
   "metadata": {},
   "source": [
    "## 4. Builder ‚Äì MusicCaps ‚Üí waveform Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09f6f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_musiccaps_waveform_parquet(\n",
    "    output_path: Path,\n",
    "    split: str = \"train\",\n",
    "    max_samples: int | None = None,\n",
    "    num_workers: int = 8,\n",
    "    tmp_audio_dir: Path | None = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Build an OFFLINE MusicCaps Parquet with clipped waveforms.\n",
    "\n",
    "    - Loads google/MusicCaps metadata.\n",
    "    - For each row:\n",
    "        * yt-dlp + ffmpeg extract [start_s, end_s] into a temp .wav.\n",
    "        * Loads waveform into memory, deletes .wav.\n",
    "        * Stores `audio` dict and logs `download_ok` + `fail_reason`.\n",
    "    - Logs summary: total, success, failures by reason.\n",
    "    - Saves successful rows to a single Parquet file.\n",
    "    \"\"\"\n",
    "    output_path = Path(output_path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if tmp_audio_dir is None:\n",
    "        tmp_audio_dir = output_path.parent / \"musiccaps_tmp\"\n",
    "    tmp_audio_dir = Path(tmp_audio_dir)\n",
    "\n",
    "    print(f\"\\nüì• Loading google/MusicCaps split='{split}'...\")\n",
    "    ds = load_dataset(\"google/MusicCaps\", split=split)\n",
    "    total = len(ds)\n",
    "    print(f\"   Total rows in MusicCaps: {total:,}\")\n",
    "\n",
    "    if max_samples is not None and max_samples < total:\n",
    "        ds = ds.select(range(max_samples))\n",
    "        print(f\"   Selected first {max_samples:,} rows.\")\n",
    "    print(f\"   Processing {len(ds):,} rows.\")\n",
    "\n",
    "    def _add_audio_dict(example: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        ytid = example[\"ytid\"]\n",
    "        start_s = float(example[\"start_s\"])\n",
    "        end_s = float(example[\"end_s\"])\n",
    "\n",
    "        waveform, sr, reason = _download_musiccaps_clip_to_array(\n",
    "            ytid=ytid,\n",
    "            start_s=start_s,\n",
    "            end_s=end_s,\n",
    "            tmp_dir=tmp_audio_dir,\n",
    "        )\n",
    "\n",
    "        ok = waveform is not None\n",
    "        example[\"download_ok\"] = ok\n",
    "        example[\"fail_reason\"] = None if ok else reason\n",
    "\n",
    "        if ok:\n",
    "            example[\"audio\"] = {\n",
    "                \"array\": waveform,\n",
    "                \"sampling_rate\": int(sr),\n",
    "            }\n",
    "        else:\n",
    "            example[\"audio\"] = None\n",
    "\n",
    "        return example\n",
    "\n",
    "    num_workers = min(cpu_count(), num_workers)\n",
    "    print(f\"\\nüéß Downloading + slicing audio using {num_workers} workers...\")\n",
    "    ds = ds.map(\n",
    "        _add_audio_dict,\n",
    "        num_proc=num_workers,\n",
    "        desc=\"MusicCaps yt-dlp ‚Üí waveform\",\n",
    "    )\n",
    "\n",
    "    # ---- Summary logs BEFORE filtering ----\n",
    "    total_rows = len(ds)\n",
    "    download_ok_list = ds[\"download_ok\"]\n",
    "    fail_reason_list = ds[\"fail_reason\"]\n",
    "\n",
    "    success_count = sum(bool(x) for x in download_ok_list)\n",
    "    fail_count = total_rows - success_count\n",
    "\n",
    "    print(\"\\nüìä Download summary (before filtering):\")\n",
    "    print(f\"   Total rows   : {total_rows:,}\")\n",
    "    print(f\"   Successful   : {success_count:,}\")\n",
    "    print(f\"   Failed       : {fail_count:,}\")\n",
    "\n",
    "    if fail_count > 0:\n",
    "        reason_counts = Counter(r or \"ok\" for r in fail_reason_list)\n",
    "        print(\"   Breakdown by reason:\")\n",
    "        for reason, cnt in sorted(reason_counts.items(), key=lambda x: (-x[1], x[0])):\n",
    "            print(f\"     - {reason:20s}: {cnt:,}\")\n",
    "\n",
    "    # ---- Filter to successful only ----\n",
    "    before = len(ds)\n",
    "    ds = ds.filter(lambda e: e[\"download_ok\"] and e[\"audio\"] is not None)\n",
    "    after = len(ds)\n",
    "    print(f\"\\n‚úÖ Rows kept for Parquet (successful only): {after:,} / {before:,}\")\n",
    "\n",
    "    if after == 0:\n",
    "        raise RuntimeError(\"No successful MusicCaps downloads. Check yt-dlp / ffmpeg / cookies.\")\n",
    "\n",
    "    # We don't need download_ok / fail_reason in the final Parquet\n",
    "    ds = ds.remove_columns([\"download_ok\", \"fail_reason\"])\n",
    "\n",
    "    # Cleanup tmp dir if any leftovers\n",
    "    if tmp_audio_dir.exists():\n",
    "        try:\n",
    "            for p in tmp_audio_dir.glob(\"*.wav\"):\n",
    "                p.unlink()\n",
    "            tmp_audio_dir.rmdir()\n",
    "        except OSError:\n",
    "            # dir not empty or other issue; fine to leave it\n",
    "            pass\n",
    "\n",
    "    print(f\"\\nüíæ Saving waveform Parquet to: {output_path}\")\n",
    "    ds.to_parquet(str(output_path))\n",
    "    print(\"üéâ MusicCaps waveform Parquet complete.\")\n",
    "    print(f\"üìå File: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77afe479",
   "metadata": {},
   "source": [
    "## 5. Run the builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c690c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(\"\\n=== Building MusicCaps waveform Parquet ===\")\n",
    "# if MUSICC_PARQUET_PATH.exists():\n",
    "#     print(f\"üìÇ Parquet already exists, skipping build: {MUSICC_PARQUET_PATH}\")\n",
    "# else:\n",
    "#     build_musiccaps_waveform_parquet(\n",
    "#         output_path=MUSICC_PARQUET_PATH,\n",
    "#         split=\"train\",\n",
    "#         max_samples=MAX_SAMPLES,\n",
    "#         num_workers=NUM_WORKERS,\n",
    "#         tmp_audio_dir=TMP_AUDIO_DIR,\n",
    "#     )\n",
    "#     print(\"‚úÖ Build complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237635d1",
   "metadata": {},
   "source": [
    "## 6. Quick sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "if MUSICC_PARQUET_PATH.exists():\n",
    "    print(\"\\nüîé Verifying MusicCaps Parquet...\")\n",
    "    musiccaps_local = load_dataset(\n",
    "        \"parquet\",\n",
    "        data_files={\"train\": str(MUSICC_PARQUET_PATH)},\n",
    "    )[\"train\"]\n",
    "\n",
    "    print(musiccaps_local)\n",
    "    print(\"Columns:\", musiccaps_local.column_names)\n",
    "\n",
    "    ex = musiccaps_local[0]\n",
    "    print(\"\\nExample audio:\")\n",
    "    print(\"  sampling_rate:\", ex[\"audio\"][\"sampling_rate\"])\n",
    "    print(\"  array shape  :\", ex[\"audio\"][\"array\"].shape)\n",
    "    print(\"  caption      :\", ex[\"caption\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62f0318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------------------------------------------------------\n",
    "# #                           MECAT‚ÄìCAPTION BUILDER\n",
    "# # -----------------------------------------------------------------------------\n",
    "# from pathlib import Path\n",
    "# from typing import Optional, Dict, Any\n",
    "\n",
    "# from datasets import load_dataset, Audio\n",
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "# def build_mecat_caption_parquet(\n",
    "#     output_path: Path,\n",
    "#     split: str = \"train\",\n",
    "#     max_samples: Optional[int] = None,\n",
    "#     sampling_rate: int = 16_000,\n",
    "#     caption_key: str = \"long\",\n",
    "# ) -> None:\n",
    "#     \"\"\"\n",
    "#     Build an OFFLINE Parquet for `mispeech/MECAT-Caption`.\n",
    "\n",
    "#     - Uses the already-packaged audio (`flac`) ‚Üí cast to Audio(sampling_rate).\n",
    "#     - Adds a flat `caption` column from the nested `json[caption_key]`.\n",
    "#     - Keeps:\n",
    "#         * __key__\n",
    "#         * audio  (Audio column)\n",
    "#         * json   (all caption variants: long/short/speech/music/sound/environment)\n",
    "#         * caption (chosen main caption)\n",
    "#     - Saves everything to a single Parquet file.\n",
    "\n",
    "#     Args:\n",
    "#         output_path: Where to save the Parquet.\n",
    "#         split: HF split to use (\"train\" or \"test\"; MECAT-Caption mainly uses \"train\").\n",
    "#         max_samples: If provided, keep at most this many rows.\n",
    "#         sampling_rate: Target sampling rate for the Audio column.\n",
    "#         caption_key: Which key inside `json` to use as the main flat `caption`\n",
    "#                      (e.g. \"long\", \"short\", \"speech\", \"music\", \"sound\", \"environment\").\n",
    "#     \"\"\"\n",
    "#     output_path = Path(output_path)\n",
    "#     output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     print(f\"\\nüì• Loading mispeech/MECAT-Caption split='{split}'...\")\n",
    "#     ds = load_dataset(\"mispeech/MECAT-Caption\", split=split)\n",
    "#     total = len(ds)\n",
    "#     print(f\"   Total rows in MECAT-Caption: {total:,}\")\n",
    "\n",
    "#     # Optional subsetting\n",
    "#     if max_samples is not None and max_samples < total:\n",
    "#         ds = ds.select(range(max_samples))\n",
    "#         print(f\"   Selected first {max_samples:,} rows.\")\n",
    "#     print(f\"   Working with {len(ds):,} rows.\")\n",
    "\n",
    "#     # Cast 'flac' to proper Audio column\n",
    "#     print(\"\\nüéß Casting 'flac' column to Audio...\")\n",
    "#     ds = ds.cast_column(\"flac\", Audio(sampling_rate=sampling_rate))\n",
    "\n",
    "#     # Add a flat `caption` column from json[caption_key]\n",
    "#     def _add_caption(example: Dict[str, Any]) -> Dict[str, Any]:\n",
    "#         j = example.get(\"json\", {}) or {}\n",
    "#         # Fallback to 'long' if chosen key is missing\n",
    "#         caption = j.get(caption_key, j.get(\"long\", \"\"))\n",
    "#         example[\"caption\"] = caption\n",
    "#         return example\n",
    "\n",
    "#     print(f\"üìù Adding 'caption' column from json['{caption_key}']...\")\n",
    "#     ds = ds.map(_add_caption, desc=\"Adding caption\")\n",
    "\n",
    "#     # Rename 'flac' -> 'audio' to match your other datasets (PixMo, MusicCaps)\n",
    "#     print(\"üîÅ Renaming 'flac' ‚Üí 'audio'...\")\n",
    "#     ds = ds.rename_column(\"flac\", \"audio\")\n",
    "\n",
    "#     # Quick preview\n",
    "#     print(\"\\nüîé Example row:\")\n",
    "#     ex = ds[0]\n",
    "#     print(\"  __key__      :\", ex.get(\"__key__\", \"\")[:80])\n",
    "#     print(\"  caption      :\", ex.get(\"caption\", \"\")[:120], \"...\")\n",
    "#     print(\"  audio.sr     :\", ex[\"audio\"][\"sampling_rate\"])\n",
    "#     print(\"  audio.shape  :\", ex[\"audio\"][\"array\"].shape)\n",
    "#     print(\"  json keys    :\", list(ex.get(\"json\", {}).keys()))\n",
    "\n",
    "#     # Save to Parquet\n",
    "#     print(f\"\\nüíæ Saving MECAT-Caption Parquet to: {output_path}\")\n",
    "#     ds.to_parquet(str(output_path))\n",
    "#     print(\"‚úÖ MECAT-Caption Parquet saved.\")\n",
    "#     print(f\"üìå File: {output_path}\")\n",
    "#     print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d9fbdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MECAT_PARQUET_PATH = Path(\"data/alignment_offline/mecat_caption.parquet\")\n",
    "\n",
    "# if MECAT_PARQUET_PATH.exists():\n",
    "#     print(f\"üìÇ MECAT Parquet already exists, skipping build: {MECAT_PARQUET_PATH}\")\n",
    "# else:\n",
    "#     build_mecat_caption_parquet(\n",
    "#         output_path=MECAT_PARQUET_PATH,\n",
    "#         split=\"train\",\n",
    "#         max_samples=20_000,\n",
    "#         sampling_rate=16_000,\n",
    "#         caption_key=\"long\",\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c993b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edge_glass_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

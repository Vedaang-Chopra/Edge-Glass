{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08052898",
   "metadata": {},
   "source": [
    "### üß± Step 1 ‚Äì Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6785cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Basic setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Choose device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90aa58",
   "metadata": {},
   "source": [
    "### üß± Step 2 ‚Äì Tiny toy ‚Äúcorpus‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd09544f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: hello world\n",
      "1: hi there\n",
      "2: how are you\n",
      "3: hello there\n",
      "4: hi world\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Tiny toy dataset (very small)\n",
    "corpus = [\n",
    "    \"hello world\",\n",
    "    \"hi there\",\n",
    "    \"how are you\",\n",
    "    \"hello there\",\n",
    "    \"hi world\",\n",
    "]\n",
    "\n",
    "for i, s in enumerate(corpus):\n",
    "    print(f\"{i}: {s}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0074bfa0",
   "metadata": {},
   "source": [
    "### üß± Step 3 ‚Äì Character-level tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25db63bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Character-level tokenizer\n",
    "\n",
    "class CharTokenizer:\n",
    "    def __init__(self):\n",
    "        # Base character set: lowercase letters + space + punctuation we need\n",
    "        base_chars = list(\"abcdefghijklmnopqrstuvwxyz ,!?\")\n",
    "\n",
    "        # Special tokens at the beginning\n",
    "        self.special_tokens = [\"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "        self.itos = self.special_tokens + base_chars  # index ‚Üí string\n",
    "        self.stoi = {ch: i for i, ch in enumerate(self.itos)}  # string ‚Üí index\n",
    "\n",
    "    @property\n",
    "    def pad_id(self):\n",
    "        return self.stoi[\"<pad>\"]\n",
    "\n",
    "    @property\n",
    "    def bos_id(self):\n",
    "        return self.stoi[\"<bos>\"]\n",
    "\n",
    "    @property\n",
    "    def eos_id(self):\n",
    "        return self.stoi[\"<eos>\"]\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def encode(self, text, add_special_tokens=True):\n",
    "        text = text.lower()\n",
    "        ids = []\n",
    "        if add_special_tokens:\n",
    "            ids.append(self.bos_id)\n",
    "        for ch in text:\n",
    "            if ch in self.stoi:\n",
    "                ids.append(self.stoi[ch])\n",
    "            # if char not in vocab, we just skip it for now\n",
    "        if add_special_tokens:\n",
    "            ids.append(self.eos_id)\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids, skip_special=True):\n",
    "        chars = []\n",
    "        special_set = set(self.special_tokens) if skip_special else set()\n",
    "        for i in ids:\n",
    "            ch = self.itos[int(i)]\n",
    "            if ch in special_set:\n",
    "                continue\n",
    "            chars.append(ch)\n",
    "        return \"\".join(chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109fd65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 33\n",
      "Token IDs of 'hello world': [1, 10, 7, 14, 14, 17, 29, 25, 17, 20, 14, 6, 2]\n",
      "Decoded back: hello world\n"
     ]
    }
   ],
   "source": [
    "tok = CharTokenizer()\n",
    "print(\"Vocab size:\", tok.vocab_size)\n",
    "print(\"Token IDs of 'hello world':\", tok.encode(\"hello world\"))\n",
    "print(\"Decoded back:\",\n",
    "      tok.decode(tok.encode(\"hello world\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806835f8",
   "metadata": {},
   "source": [
    "### üß± Step 4 ‚Äì Build a small batch of token IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67925555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded sequences:\n",
      "'hello world' -> [1, 10, 7, 14, 14, 17, 29, 25, 17, 20, 14, 6, 2]\n",
      "'hi there' -> [1, 10, 11, 29, 22, 10, 7, 20, 7, 2]\n",
      "'how are you' -> [1, 10, 17, 25, 29, 3, 20, 7, 29, 27, 17, 23, 2]\n",
      "'hello there' -> [1, 10, 7, 14, 14, 17, 29, 22, 10, 7, 20, 7, 2]\n",
      "'hi world' -> [1, 10, 11, 29, 25, 17, 20, 14, 6, 2]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Encode the corpus and create a padded batch\n",
    "\n",
    "# Encode each sentence\n",
    "encoded = [tok.encode(s) for s in corpus]\n",
    "print(\"Encoded sequences:\")\n",
    "for s, ids in zip(corpus, encoded):\n",
    "    print(f\"{s!r} -> {ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cd64377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 13\n"
     ]
    }
   ],
   "source": [
    "# Find max length\n",
    "max_len = max(len(ids) for ids in encoded)\n",
    "print(\"Max length:\", max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c279df3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad with <pad> so all sequences = max_len\n",
    "pad_id = tok.pad_id\n",
    "padded = [ids + [pad_id] * (max_len - len(ids)) for ids in encoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38313ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([5, 13])\n",
      "tensor([[ 1, 10,  7, 14, 14, 17, 29, 25, 17, 20, 14,  6,  2],\n",
      "        [ 1, 10, 11, 29, 22, 10,  7, 20,  7,  2,  0,  0,  0],\n",
      "        [ 1, 10, 17, 25, 29,  3, 20,  7, 29, 27, 17, 23,  2],\n",
      "        [ 1, 10,  7, 14, 14, 17, 29, 22, 10,  7, 20,  7,  2],\n",
      "        [ 1, 10, 11, 29, 25, 17, 20, 14,  6,  2,  0,  0,  0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensor (B, T)\n",
    "input_ids = torch.tensor(padded, dtype=torch.long, device=device)\n",
    "print(\"input_ids shape:\", input_ids.shape)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a94539",
   "metadata": {},
   "source": [
    "### üß© Step 5 ‚Äì Model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b76b126b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTConfig(vocab_size=33, d_model=64, n_heads=4, n_layers=2, block_size=13, dropout=0.1)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Model config\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    vocab_size: int\n",
    "    d_model: int = 64      # embedding size\n",
    "    n_heads: int = 4       # number of attention heads\n",
    "    n_layers: int = 2      # transformer blocks\n",
    "    block_size: int = 32   # max sequence length\n",
    "    dropout: float = 0.1\n",
    "\n",
    "cfg = GPTConfig(\n",
    "    vocab_size=tok.vocab_size,\n",
    "    d_model=64,\n",
    "    n_heads=4,\n",
    "    n_layers=2,\n",
    "    block_size=input_ids.shape[1],  # just use current max length\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "print(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1560ca1f",
   "metadata": {},
   "source": [
    "### üß© Step 6 ‚Äì Embedding layer (token + position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca4bf7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding output shape: torch.Size([5, 13, 64])\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Embedding module (token + positional)\n",
    "\n",
    "class TokenPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, cfg: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.tok_emb = nn.Embedding(cfg.vocab_size, cfg.d_model)\n",
    "        self.pos_emb = nn.Embedding(cfg.block_size, cfg.d_model)\n",
    "        self.dropout = nn.Dropout(cfg.dropout)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"\n",
    "        input_ids: (B, T) of token indices\n",
    "        returns: (B, T, d_model)\n",
    "        \"\"\"\n",
    "        B, T = input_ids.shape\n",
    "        device = input_ids.device\n",
    "\n",
    "        # 1) Token embeddings: (B, T, d_model)\n",
    "        tok = self.tok_emb(input_ids)\n",
    "\n",
    "        # 2) Positional embeddings:\n",
    "        # positions = [0, 1, ..., T-1]\n",
    "        positions = torch.arange(T, device=device).unsqueeze(0)  # (1, T)\n",
    "        pos = self.pos_emb(positions)  # (1, T, d_model) broadcast over B\n",
    "\n",
    "        # 3) Add them\n",
    "        x = tok + pos\n",
    "\n",
    "        # 4) Optional dropout\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Instantiate and test\n",
    "embed = TokenPositionalEmbedding(cfg).to(device)\n",
    "x = embed(input_ids)  # (B, T, d_model)\n",
    "print(\"Embedding output shape:\", x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72295408",
   "metadata": {},
   "source": [
    "### üß© Step 7 ‚Äì Causal Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d0dd844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Causal self-attention\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        assert cfg.d_model % cfg.n_heads == 0, \"d_model must be divisible by n_heads\"\n",
    "        self.cfg = cfg\n",
    "        self.n_heads = cfg.n_heads\n",
    "        self.head_dim = cfg.d_model // cfg.n_heads\n",
    "\n",
    "        # One linear layer to get Q, K, V together: (d_model -> 3 * d_model)\n",
    "        self.qkv = nn.Linear(cfg.d_model, 3 * cfg.d_model)\n",
    "        self.proj = nn.Linear(cfg.d_model, cfg.d_model)\n",
    "        self.dropout = nn.Dropout(cfg.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, T, d_model)\n",
    "        returns: (B, T, d_model)\n",
    "        \"\"\"\n",
    "        B, T, C = x.shape  # C = d_model\n",
    "\n",
    "        # 1) Project to Q, K, V\n",
    "        qkv = self.qkv(x)               # (B, T, 3C)\n",
    "        q, k, v = qkv.chunk(3, dim=-1)  # each: (B, T, C)\n",
    "\n",
    "        # 2) Reshape for multi-head: (B, n_heads, T, head_dim)\n",
    "        q = q.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        k = k.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # 3) Attention scores: Q K^T / sqrt(d_head)\n",
    "        att = q @ k.transpose(-2, -1)   # (B, n_heads, T, T)\n",
    "        att = att / (self.head_dim ** 0.5)\n",
    "\n",
    "        # 4) Build causal mask so position t cannot see > t\n",
    "        mask = torch.tril(torch.ones(T, T, device=x.device))\n",
    "        # mask: (T, T) ‚Üí lower triangle = 1, upper = 0\n",
    "        mask = mask.view(1, 1, T, T)    # (1,1,T,T) broadcast over B and heads\n",
    "\n",
    "        att = att.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        # 5) Softmax ‚Üí probabilities over source positions\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.dropout(att)\n",
    "\n",
    "        # 6) Weighted sum of values\n",
    "        y = att @ v                     # (B, n_heads, T, head_dim)\n",
    "\n",
    "        # 7) Merge heads back\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)  # (B,T,C)\n",
    "\n",
    "        # 8) Final projection\n",
    "        y = self.proj(y)\n",
    "        y = self.dropout(y)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcf0c6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention output shape: torch.Size([5, 13, 64])\n"
     ]
    }
   ],
   "source": [
    "attn = CausalSelfAttention(cfg).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = attn(x)  # x from: x = embed(input_ids)\n",
    "print(\"Attention output shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba42fab",
   "metadata": {},
   "source": [
    "### üß© Step 8 ‚Äì Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73582960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Transformer Block (Attention + MLP + residuals)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(cfg.d_model)\n",
    "        self.attn = CausalSelfAttention(cfg)\n",
    "        self.ln2 = nn.LayerNorm(cfg.d_model)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(cfg.d_model, 4 * cfg.d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * cfg.d_model, cfg.d_model),\n",
    "            nn.Dropout(cfg.dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, d_model)\n",
    "\n",
    "        # 1) Attention sub-layer\n",
    "        x = x + self.attn(self.ln1(x))   # LN ‚Üí Attn ‚Üí add residual\n",
    "\n",
    "        # 2) MLP sub-layer\n",
    "        x = x + self.mlp(self.ln2(x))    # LN ‚Üí MLP ‚Üí add residual\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e960eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block output shape: torch.Size([5, 13, 64])\n"
     ]
    }
   ],
   "source": [
    "block = Block(cfg).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_block = block(x)  # x from embedding layer\n",
    "print(\"Block output shape:\", x_block.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f899e8",
   "metadata": {},
   "source": [
    "### üß© Step 9 ‚Äì Full Decoder-only LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa3b4033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Full tiny decoder-only LLM\n",
    "\n",
    "class DecoderOnlyLM(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.embed = TokenPositionalEmbedding(cfg)\n",
    "        self.blocks = nn.ModuleList([Block(cfg) for _ in range(cfg.n_layers)])\n",
    "        self.ln_f = nn.LayerNorm(cfg.d_model)\n",
    "        self.lm_head = nn.Linear(cfg.d_model, cfg.vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, input_ids, targets=None):\n",
    "        \"\"\"\n",
    "        input_ids: (B, T) token IDs\n",
    "        targets: (B, T) token IDs for computing next-token loss (optional)\n",
    "        returns: logits (B, T, vocab_size), loss (or None)\n",
    "        \"\"\"\n",
    "        B, T = input_ids.shape\n",
    "\n",
    "        # 1) Embedding: tokens + positions ‚Üí (B, T, d_model)\n",
    "        x = self.embed(input_ids)\n",
    "\n",
    "        # 2) Transformer blocks\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        # 3) Final LayerNorm\n",
    "        x = self.ln_f(x)\n",
    "\n",
    "        # 4) LM head: per-token distribution over vocab\n",
    "        logits = self.lm_head(x)   # (B, T, vocab_size)\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            # Next-token prediction:\n",
    "            # logits for positions 0..T-2 predict targets at 1..T-1\n",
    "            logits_shifted = logits[:, :-1, :].contiguous()   # (B, T-1, V)\n",
    "            targets_shifted = targets[:, 1:].contiguous()     # (B, T-1)\n",
    "\n",
    "            loss = F.cross_entropy(\n",
    "                logits_shifted.view(-1, logits_shifted.size(-1)),\n",
    "                targets_shifted.view(-1),\n",
    "                ignore_index=tok.pad_id,  # don't penalize pad tokens\n",
    "            )\n",
    "\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3492559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([5, 13, 33])\n",
      "Initial loss: 3.646306276321411\n"
     ]
    }
   ],
   "source": [
    "model = DecoderOnlyLM(cfg).to(device)\n",
    "\n",
    "logits, loss = model(input_ids, targets=input_ids)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Initial loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0490feea",
   "metadata": {},
   "source": [
    "### üß© Step 10 ‚Äì Simple training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc6dd0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   1 | loss = 3.5746\n",
      "Step  50 | loss = 0.3736\n",
      "Step 100 | loss = 0.1986\n",
      "Step 150 | loss = 0.1684\n",
      "Step 200 | loss = 0.1640\n",
      "Step 250 | loss = 0.1525\n",
      "Step 300 | loss = 0.1584\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Simple training loop\n",
    "\n",
    "# Reuse: model, cfg, input_ids, tok from before\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_steps = 300  # keep small at first\n",
    "\n",
    "model.train()\n",
    "for step in range(1, num_steps + 1):\n",
    "    # Forward pass: we use input_ids as both inputs and targets\n",
    "    logits, loss = model(input_ids, targets=input_ids)\n",
    "\n",
    "    # Backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print every 50 steps\n",
    "    if step % 50 == 0 or step == 1:\n",
    "        print(f\"Step {step:3d} | loss = {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8259b78",
   "metadata": {},
   "source": [
    "### üß© Step 11 ‚Äì Add a generate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84cce906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Text generation helper\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_text(model, tok, prompt, max_new_tokens=20, greedy=True):\n",
    "    model.eval()\n",
    "\n",
    "    # 1) Encode prompt\n",
    "    ids = tok.encode(prompt)  # includes <bos> and <eos>\n",
    "    # we don't want to stop at eos yet, so let's drop eos\n",
    "    if tok.eos_id in ids:\n",
    "        ids = ids[:-1]\n",
    "\n",
    "    input_ids_gen = torch.tensor([ids], dtype=torch.long, device=device)  # (1, T)\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        # 2) Run model to get logits\n",
    "        logits, _ = model(input_ids_gen)  # (1, T, vocab_size)\n",
    "        last_logits = logits[:, -1, :]   # (1, vocab_size)\n",
    "\n",
    "        # 3) Turn logits into probabilities\n",
    "        probs = F.softmax(last_logits, dim=-1)  # (1, vocab_size)\n",
    "\n",
    "        # 4) Choose next token\n",
    "        if greedy:\n",
    "            next_id = probs.argmax(dim=-1, keepdim=True)  # (1,1)\n",
    "        else:\n",
    "            next_id = torch.multinomial(probs, num_samples=1)  # (1,1)\n",
    "\n",
    "        # 5) Append to sequence\n",
    "        input_ids_gen = torch.cat([input_ids_gen, next_id], dim=1)\n",
    "\n",
    "        # Optional: stop if we hit eos\n",
    "        if next_id.item() == tok.eos_id:\n",
    "            break\n",
    "\n",
    "    # Decode the whole sequence (skip special tokens)\n",
    "    output_text = tok.decode(input_ids_gen[0].tolist())\n",
    "    return output_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004653ab",
   "metadata": {},
   "source": [
    "### üß© Step 12 ‚Äì Try generating some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e0f67e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'h' -> 'hi there'\n",
      "Prompt: 'hello' -> 'hello world'\n",
      "Prompt: 'hi' -> 'hi there'\n",
      "Prompt: 'how' -> 'how are you'\n",
      "Prompt: 'he' -> 'hello world'\n"
     ]
    }
   ],
   "source": [
    "# Try a few prompts\n",
    "\n",
    "prompts = [\"h\", \"hello\", \"hi\", \"how\", \"he\"]\n",
    "\n",
    "for p in prompts:\n",
    "    out = generate_text(model, tok, p, max_new_tokens=20, greedy=True)\n",
    "    print(f\"Prompt: {p!r} -> {out!r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e9cc915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tok, \"hello\", max_new_tokens=20, greedy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bafe4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edge_glass_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

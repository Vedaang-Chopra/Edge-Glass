{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587479f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Hugging Face\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Utils\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31184bb",
   "metadata": {},
   "source": [
    "### 1. Choose a text-only dataset (STS-B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce42db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STS-B from GLUE\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "raw_datasets = load_dataset(\"glue\", \"stsb\")\n",
    "raw_datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f3c9e",
   "metadata": {},
   "source": [
    "### Load a good text encoder (frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db4250",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "base_model = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "# We'll freeze the base model's parameters\n",
    "for p in base_model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "base_model.eval()\n",
    "base_model.hidden_size = base_model.config.hidden_size\n",
    "base_model.hidden_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c54498",
   "metadata": {},
   "source": [
    "### Sentence embedding function (mean pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50f5ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pool(last_hidden_state, attention_mask):\n",
    "    # last_hidden_state: (B, T, H)\n",
    "    # attention_mask: (B, T)\n",
    "    mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)  # (B, T, 1)\n",
    "    summed = (last_hidden_state * mask).sum(dim=1)\n",
    "    counts = mask.sum(dim=1).clamp(min=1e-9)\n",
    "    return summed / counts\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_sentences(texts, batch_model=base_model, batch_tokenizer=tokenizer, device=\"cpu\"):\n",
    "    enc = batch_tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    outputs = batch_model(**enc)\n",
    "    sentence_embeddings = mean_pool(outputs.last_hidden_state, enc[\"attention_mask\"])\n",
    "    return sentence_embeddings  # (B, hidden_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd43cbe",
   "metadata": {},
   "source": [
    "### Build a PyTorch-friendly dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f21b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_datasets[\"train\"]\n",
    "val_ds   = raw_datasets[\"validation\"]\n",
    "\n",
    "def stsb_collate(batch, tokenizer=tokenizer, device=\"cpu\"):\n",
    "    s1 = [b[\"sentence1\"] for b in batch]\n",
    "    s2 = [b[\"sentence2\"] for b in batch]\n",
    "    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.float32)\n",
    "\n",
    "    enc1 = tokenizer(\n",
    "        s1, padding=True, truncation=True, max_length=64, return_tensors=\"pt\"\n",
    "    )\n",
    "    enc2 = tokenizer(\n",
    "        s2, padding=True, truncation=True, max_length=64, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    batch_enc = {\n",
    "        \"input_ids_1\": enc1[\"input_ids\"],\n",
    "        \"attention_mask_1\": enc1[\"attention_mask\"],\n",
    "        \"input_ids_2\": enc2[\"input_ids\"],\n",
    "        \"attention_mask_2\": enc2[\"attention_mask\"],\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "    return {k: v.to(device) for k, v in batch_enc.items()}\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda b: stsb_collate(b, device=device),\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda b: stsb_collate(b, device=device),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a12b433",
   "metadata": {},
   "source": [
    "### Define the Linear projector for alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6525ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearProjector(nn.Module):\n",
    "    def __init__(self, in_dim, proj_dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(in_dim, proj_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.proj(x)\n",
    "        z = F.normalize(z, p=2, dim=-1)\n",
    "        return z\n",
    "\n",
    "proj_dim = 256\n",
    "projector = LinearProjector(base_model.hidden_size, proj_dim).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca0f02",
   "metadata": {},
   "source": [
    "### Contrastive loss (InfoNCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e2a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(z1, z2, temperature=0.07):\n",
    "    \"\"\"\n",
    "    z1, z2: (B, D) normalized\n",
    "    \"\"\"\n",
    "    batch_size = z1.size(0)\n",
    "    logits = z1 @ z2.t()  # (B, B)\n",
    "    logits = logits / temperature\n",
    "\n",
    "    labels = torch.arange(batch_size, device=z1.device)\n",
    "\n",
    "    loss_i = F.cross_entropy(logits, labels)         # z1 -> z2\n",
    "    loss_j = F.cross_entropy(logits.t(), labels)     # z2 -> z1\n",
    "\n",
    "    return (loss_i + loss_j) / 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d46aa56",
   "metadata": {},
   "source": [
    "### Training loop (text-only linear projector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bbff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10  # start small\n",
    "LR = 1e-3\n",
    "\n",
    "projector.train()\n",
    "optimizer = torch.optim.AdamW(projector.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    for batch in pbar:\n",
    "        # 1. Encode sentences with frozen encoder\n",
    "        batch = {\n",
    "        k: v.to(device)\n",
    "        for k, v in batch.items()\n",
    "        if isinstance(v, torch.Tensor)\n",
    "    }\n",
    "        with torch.no_grad():\n",
    "            outputs1 = base_model(\n",
    "                input_ids=batch[\"input_ids_1\"],\n",
    "                attention_mask=batch[\"attention_mask_1\"],\n",
    "            )\n",
    "            h1 = mean_pool(outputs1.last_hidden_state, batch[\"attention_mask_1\"])\n",
    "\n",
    "            outputs2 = base_model(\n",
    "                input_ids=batch[\"input_ids_2\"],\n",
    "                attention_mask=batch[\"attention_mask_2\"],\n",
    "            )\n",
    "            h2 = mean_pool(outputs2.last_hidden_state, batch[\"attention_mask_2\"])\n",
    "\n",
    "        # 2. Project into shared space\n",
    "        z1 = projector(h1)\n",
    "        z2 = projector(h2)\n",
    "\n",
    "        # 3. Contrastive loss\n",
    "        loss = contrastive_loss(z1, z2, temperature=0.07)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({\"loss\": total_loss / (len(pbar)+1e-9)})\n",
    "\n",
    "    print(f\"Epoch {epoch+1} done. Avg loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed0fc7c",
   "metadata": {},
   "source": [
    "### Quick evaluation: STS-B Spearman correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45537322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "projector.eval()\n",
    "\n",
    "all_scores = []\n",
    "all_sims   = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader, desc=\"Eval\"):\n",
    "        outputs1 = base_model(\n",
    "            input_ids=batch[\"input_ids_1\"],\n",
    "            attention_mask=batch[\"attention_mask_1\"],\n",
    "        )\n",
    "        h1 = mean_pool(outputs1.last_hidden_state, batch[\"attention_mask_1\"])\n",
    "\n",
    "        outputs2 = base_model(\n",
    "            input_ids=batch[\"input_ids_2\"],\n",
    "            attention_mask=batch[\"attention_mask_2\"],\n",
    "        )\n",
    "        h2 = mean_pool(outputs2.last_hidden_state, batch[\"attention_mask_2\"])\n",
    "\n",
    "        z1 = projector(h1)\n",
    "        z2 = projector(h2)\n",
    "\n",
    "        sims = F.cosine_similarity(z1, z2, dim=-1).cpu().numpy()\n",
    "        labels = batch[\"labels\"].cpu().numpy()\n",
    "\n",
    "        all_sims.append(sims)\n",
    "        all_scores.append(labels)\n",
    "\n",
    "all_sims = np.concatenate(all_sims)\n",
    "all_scores = np.concatenate(all_scores)\n",
    "\n",
    "corr, _ = spearmanr(all_sims, all_scores)\n",
    "print(f\"Spearman correlation (val): {corr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b52a64",
   "metadata": {},
   "source": [
    "## Training with an MLP projector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d2a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPProjector(nn.Module):\n",
    "    def __init__(self, in_dim, proj_dim, hidden_dim=None):\n",
    "        super().__init__()\n",
    "        if hidden_dim is None:\n",
    "            hidden_dim = proj_dim * 2  # simple heuristic\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, proj_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.net(x)\n",
    "        z = F.normalize(z, p=2, dim=-1)\n",
    "        return z\n",
    "\n",
    "proj_dim = 256\n",
    "projector = MLPProjector(base_model.hidden_size, proj_dim).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8911c70f",
   "metadata": {},
   "source": [
    "### Training Loop (Same as Before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d3008",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "LR = 1e-3\n",
    "\n",
    "projector.train()\n",
    "optimizer = torch.optim.AdamW(projector.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    pbar = tqdm(train_loader, desc=f\"MLP Projector — Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    for batch in pbar:\n",
    "        with torch.no_grad():\n",
    "            o1 = base_model(\n",
    "                input_ids=batch[\"input_ids_1\"],\n",
    "                attention_mask=batch[\"attention_mask_1\"]\n",
    "            )\n",
    "            h1 = mean_pool(o1.last_hidden_state, batch[\"attention_mask_1\"])\n",
    "\n",
    "            o2 = base_model(\n",
    "                input_ids=batch[\"input_ids_2\"],\n",
    "                attention_mask=batch[\"attention_mask_2\"]\n",
    "            )\n",
    "            h2 = mean_pool(o2.last_hidden_state, batch[\"attention_mask_2\"])\n",
    "\n",
    "        z1 = projector(h1)\n",
    "        z2 = projector(h2)\n",
    "\n",
    "        loss = contrastive_loss(z1, z2)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({\"loss\": total_loss / (len(pbar)+1e-9)})\n",
    "\n",
    "    print(f\"Epoch {epoch+1} — Avg Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf6b9b2",
   "metadata": {},
   "source": [
    "### Evaluation (Same STS-B Spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419d8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "projector.eval()\n",
    "\n",
    "all_scores = []\n",
    "all_sims = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader, desc=\"Evaluating MLP Projector\"):\n",
    "        o1 = base_model(\n",
    "            input_ids=batch[\"input_ids_1\"],\n",
    "            attention_mask=batch[\"attention_mask_1\"]\n",
    "        )\n",
    "        h1 = mean_pool(o1.last_hidden_state, batch[\"attention_mask_1\"])\n",
    "\n",
    "        o2 = base_model(\n",
    "            input_ids=batch[\"input_ids_2\"],\n",
    "            attention_mask=batch[\"attention_mask_2\"]\n",
    "        )\n",
    "        h2 = mean_pool(o2.last_hidden_state, batch[\"attention_mask_2\"])\n",
    "\n",
    "        z1 = projector(h1)\n",
    "        z2 = projector(h2)\n",
    "\n",
    "        sims = F.cosine_similarity(z1, z2, dim=-1).cpu().numpy()\n",
    "        labels = batch[\"labels\"].cpu().numpy()\n",
    "\n",
    "        all_sims.append(sims)\n",
    "        all_scores.append(labels)\n",
    "\n",
    "all_sims = np.concatenate(all_sims)\n",
    "all_scores = np.concatenate(all_scores)\n",
    "\n",
    "corr, _ = spearmanr(all_sims, all_scores)\n",
    "print(f\"Spearman correlation (val): {corr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1820ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(all_sims, bins=50, alpha=0.7, color='blue')\n",
    "plt.title(\"Cosine similarity distribution — MLP Projector\")\n",
    "plt.xlabel(\"Cosine similarity\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edge_glass_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bcf6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b80b76e",
   "metadata": {},
   "source": [
    "### Phase-0: - Load Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c0d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import setup_from_yaml, ModelsConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de75418c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">phase0_global_setup</strong> at: <a href='https://wandb.ai/vedaangchopra_gatech/edge_glass/runs/ey77wu3o' target=\"_blank\">https://wandb.ai/vedaangchopra_gatech/edge_glass/runs/ey77wu3o</a><br> View project at: <a href='https://wandb.ai/vedaangchopra_gatech/edge_glass' target=\"_blank\">https://wandb.ai/vedaangchopra_gatech/edge_glass</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251122_194825-ey77wu3o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/storage/ice1/1/0/vchopra37/projects/edge_glass/code_base/wandb/run-20251122_194959-shsdkk6d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vedaangchopra_gatech/edge_glass/runs/shsdkk6d' target=\"_blank\">phase0_global_setup</a></strong> to <a href='https://wandb.ai/vedaangchopra_gatech/edge_glass' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vedaangchopra_gatech/edge_glass' target=\"_blank\">https://wandb.ai/vedaangchopra_gatech/edge_glass</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vedaangchopra_gatech/edge_glass/runs/shsdkk6d' target=\"_blank\">https://wandb.ai/vedaangchopra_gatech/edge_glass/runs/shsdkk6d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config] Device: cuda, dtype: torch.float16\n",
      "[Config] root_dir: /storage/ice1/1/0/vchopra37/projects/edge_glass/code_base/edge_glass\n",
      "[Config] features_dir: /storage/ice1/1/0/vchopra37/projects/edge_glass/code_base/edge_glass/features\n",
      "Using device: cuda\n",
      "Using dtype: torch.float16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ðŸ”¹ Phase 0 â€“ Global setup\n",
    "cfg = setup_from_yaml(\"configs/config.yaml\")\n",
    "\n",
    "device = cfg.torch_device\n",
    "dtype = cfg.torch_dtype\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "print(\"Using dtype:\", dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebff6249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later, when you build encoders / perceiver:\n",
    "# from models_oop import ModelConfig, ImageEncoder, AudioEncoder, DecoderLLM\n",
    "\n",
    "# vision_model_cfg = ModelConfig(\n",
    "#     model_name=cfg.models.vision_model_name,\n",
    "#     device=str(cfg.torch_device),\n",
    "#     dtype=cfg.torch_dtype,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0f753c",
   "metadata": {},
   "source": [
    "### Phase-1: - Loading the Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6a0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.audio_encoder import load_audio_encoder\n",
    "from architecture.image_encoder import load_image_encoder\n",
    "from architecture.text_decoder import (\n",
    "    load_decoder_llm,\n",
    "    TextDecoder,\n",
    "    AudioDecoder,\n",
    "    VideoDecoder,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "489e89d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "# Image Encoders\n",
    "# Example: create encoders\n",
    "img_enc = load_image_encoder(\"openai/clip-vit-base-patch32\")\n",
    "aud_enc = load_audio_encoder(\"openai/whisper-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc33e2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7368a21a04a4ce7b87ab1818dfa39cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a72daabed240f8a4c5a1a20374b9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b30716d3df473d9564dd9b28e3bc0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb1d262ee5e457aa06875dc3ac74b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6129a899cc9e4e6cbb874ca67769f125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829da9890e41477b8d1ed33990d48948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c17b2980ea4bc9b280e9e937417b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50778d4b2bd74869a296f569fcd91162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4107267c9f00463ba562011efc874ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867f34b0f7da4fedaba9d57bdbc27055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ddd525109742bfb9f97e90f31ba9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Decoder LLM\n",
    "llm = load_decoder_llm(\"microsoft/Phi-3-mini-4k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f17a5428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contrastive learning is a machine learning technique used to teach computers to understand similarities and differences. Imagine you have a photo of a cat and you want to teach a computer to recognize that it's a cat. Contrastive learning helps the computer learn by comparing the cat photo with other images. It shows the computer which features make the cat unique, like its whiskers or fur, and which features are common in other pictures, like having four legs or ears. By looking at differences and similarities, the computer gets better at telling what the cat is without being explicitly told.\n",
      "\n",
      "Input:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_dec = TextDecoder(llm)\n",
    "audio_dec = AudioDecoder(llm)\n",
    "video_dec = VideoDecoder(llm)\n",
    "\n",
    "# Call directly\n",
    "print(text_dec(\"Explain contrastive learning in simple terms.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d425d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "dummy_img = Image.new(\"RGB\", (224, 224), color=(128, 128, 128))\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = img_enc(images=dummy_img, return_tensors=\"pt\").to(device)\n",
    "    outputs = vision_model(**inputs)\n",
    "\n",
    "last_hidden = outputs.last_hidden_state          # (batch, seq_len, dim)\n",
    "all_hidden = outputs.hidden_states               # tuple of (layer+embedding) states\n",
    "\n",
    "print(\"last_hidden.shape:\", last_hidden.shape)\n",
    "print(\"num hidden_states:\", len(all_hidden))\n",
    "print(\"hidden[0].shape (embeddings):\", all_hidden[0].shape)\n",
    "print(\"hidden[-1].shape (last layer):\", all_hidden[-1].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0456cd0",
   "metadata": {},
   "source": [
    "### Phase-2: - Preparing Pixmo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb2174f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988eebc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cf1c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb4be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73853f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2eb380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86739a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b47aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab2624a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edge_glass_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

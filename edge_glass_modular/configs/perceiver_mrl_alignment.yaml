name: perceiver_mrl_alignment
description: Vision-Text alignment with Perceiver + MRL on Pixmo
seed: 42

# Dataset (PixMo parquet)
dataset:
  name: pixmo_parquet
  train_parquet: /home/hice1/vchopra37/scratch/projects/edge_glass/dataset/final_dataset/pixmo/pixmo_train.parquet
  val_parquet: /home/hice1/vchopra37/scratch/projects/edge_glass/dataset/final_dataset/pixmo/pixmo_val.parquet
  test_parquet: /home/hice1/vchopra37/scratch/projects/edge_glass/dataset/final_dataset/pixmo/pixmo_test.parquet
  image_size: 336
  max_text_length: 77
  text_dropout_prob: 0.1
  batch_size: 64
  base_batch_size: 64
  num_workers: 8
  prefetch_factor: 2
  pin_memory: true
  persistent_workers: true

# Vision Encoder with Perceiver
vision_encoder:
  model_name: openai/clip-vit-large-patch14-336
  freeze: true
  trainable: false
  projection_dim: 4096  # Top MRL dimension = Qwen hidden size
  use_perceiver: true
  perceiver_num_latents: 64
  perceiver_latent_dim: 1024
  perceiver_num_layers: 4
  perceiver_num_heads: 8
  perceiver_dropout: 0.0
  use_mrl: true
  mrl_dimensions: [3072, 2048, 1536, 1024, 768, 512]  # MRL dims (excluding top 4096)
  use_attention_pooling: false  # Perceiver handles pooling
  pooling_type: mean

# Text Encoder
text_encoder:
  model_name: openai/clip-vit-large-patch14-336
  freeze: true
  trainable: false
  projection_dim: 4096
  use_mrl: true
  mrl_dimensions: [3072, 2048, 1536, 1024, 768, 512]

# Decoder (LLM)
decoder:
  type: qwen
  model_name: Qwen/Qwen2.5-7B-Instruct
  use_lora: true
  lora_r: 64
  lora_alpha: 128
  lora_dropout: 0.05
  lora_target_modules: ["q_proj", "v_proj", "k_proj", "o_proj"]
  load_in_8bit: false
  load_in_4bit: false

# Fusion
fusion: null

# Loss Configuration
losses:
  contrastive: 0.25  # CLIP weight
  mrl: 1.0  # MRL weight
  sample_single_mrl_dim: true

# Optimization
optimization:
  lr: 0.002
  learning_rate: 0.002
  weight_decay: 0.01
  betas: [0.9, 0.95]
  gradient_clip: 1.0
  max_grad_norm: 1.0
  grad_accum_steps: 1
  mixed_precision: bf16
  warmup_ratio: 0.1
  warmup_steps: null
  total_steps: null
  lr_scheduler: cosine
  min_lr_ratio: 0.1
  fp16: false
  bf16: true
  contrastive_loss_weight: 0.25
  mrl_loss_weight: 1.0
  lm_loss_weight: 1.0

# Training
trainer:
  epochs: 10
  num_epochs: 10
  batch_size: 128
  output_dir: ./outputs/perceiver_mrl_alignment
  ckpt_dir: ./checkpoints/perceiver_mrl_alignment
  save_every: 20
  log_every: 50
  devices: 1
  strategy: ddp
  use_wandb: true
  wandb_project: edge_glass_alignment
  wandb_run_name: perceiver_mrl_alignment
  retrieval_eval_samples: 100
  eval_batch_size: 128
  save_optimizer_state: true
  best_weights_only: true

training:
  num_epochs: 10
  output_dir: ./outputs/perceiver_mrl_alignment
  save_steps: 500
  logging_steps: 50
  eval_steps: 500
  warmup_steps: null
  gradient_accumulation_steps: 1
  wandb_project: edge_glass_alignment
  wandb_run_name: perceiver_mrl_alignment

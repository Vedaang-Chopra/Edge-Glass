name: base_alignment
dataset:
  name: pixmo_offline
  batch_size: 32
  cache_dir: ./checkpoints/datasets
  image_root: pixmo_cap
text_encoder:
  model_name: sentence-transformers/all-MiniLM-L6-v2
  projection_dim: 1024
  use_mrl: true
  mrl_dimensions: [512, 256, 128]
vision_encoder:
  model_name: openai/clip-vit-large-patch14
  projection_dim: 1024
  trainable: false
losses:
  contrastive: 1.0
  mrl: 0.05
optimization:
  lr: 0.0002
  weight_decay: 0.01
  warmup_steps: 2000
  grad_accum_steps: 4
trainer:
  epochs: 3
  batch_size: 32
  save_every: 1000
  log_every: 50
  ckpt_dir: ./checkpoints/vision_text
  devices: 2
  strategy: ddp

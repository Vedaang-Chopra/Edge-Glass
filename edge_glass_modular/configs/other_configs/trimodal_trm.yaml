# Tri-Modal with TRM Decoder
# Experiment 3: Vision + Audio + Text with lightweight TRM decoder

name: trimodal_trm
description: "Tri-modal alignment with Tiny Recursive Model (TRM) decoder"
tags: [vision, audio, text, trm, trimodal, lightweight]

# Vision Encoder
vision_encoder:
  model_name: "openai/clip-vit-base-patch16"  # Smaller for TRM experiments
  projection_dim: 1024
  freeze: true
  use_perceiver: true
  perceiver_num_latents: 32  # Fewer latents for TRM
  perceiver_latent_dim: 512
  perceiver_num_layers: 2
  perceiver_num_heads: 8
  use_mrl: false  # Disable MRL for TRM baseline
  mrl_dimensions: []

# Audio Encoder
audio_encoder:
  model_name: "openai/whisper-base"  # Smaller Whisper
  projection_dim: 1024
  freeze: true
  use_perceiver: true
  perceiver_num_latents: 32
  perceiver_latent_dim: 512
  perceiver_num_layers: 2
  perceiver_num_heads: 8
  use_mrl: false
  mrl_dimensions: []

# Text Encoder
text_encoder:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  projection_dim: 1024
  freeze: true
  use_mrl: false
  mrl_dimensions: []

# TRM Decoder
decoder:
  type: "trm"
  freeze: false

  # TRM-specific configuration
  trm_vocab_size: 32000
  trm_hidden_dim: 512
  trm_num_layers: 6
  trm_num_heads: 8
  trm_max_seq_len: 2048

# Fusion - simpler for TRM
fusion:
  strategy: "concat"
  fusion_dim: 1024
  num_fusion_layers: 2
  num_heads: 8
  dropout: 0.1

# Dataset
dataset:
  data_dir: "./data"
  cache_dir: "./cache"
  use_vision: true
  use_audio: true
  use_text: true
  num_train_samples: 20000
  num_val_samples: 2000
  batch_size: 64  # Larger batch for smaller model
  num_workers: 8
  image_size: 224
  audio_sample_rate: 16000
  audio_max_duration: 10.0
  max_text_length: 512
  instruction_dataset: "Open-Orca/OpenOrca"
  instruction_samples: 30000

# Optimization - higher LR for TRM
optimization:
  optimizer: "adamw"
  learning_rate: 5.0e-4
  weight_decay: 0.01
  lr_scheduler: "cosine"
  warmup_steps: 500
  max_grad_norm: 1.0
  gradient_accumulation_steps: 1
  mixed_precision: "bf16"
  contrastive_loss_weight: 1.0
  mrl_loss_weight: 0.0  # No MRL
  lm_loss_weight: 1.0

# Training
training:
  num_epochs: 10  # More epochs for smaller model
  eval_steps: 250
  save_steps: 500
  logging_steps: 50
  output_dir: "./checkpoints/trimodal_trm"
  save_total_limit: 5
  seed: 42
  wandb_project: "edge-glass"
  wandb_run_name: "trimodal-trm"

mode: "instruction_tuning"
use_instruction_tuning: true
